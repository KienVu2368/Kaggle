{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/home/zero/fastai'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data processing func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scale_vars(df, mapper, scale_col_exc):\n",
    "    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n",
    "    if mapper is None:\n",
    "        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n]) and n not in scale_col_exc]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    df[mapper.transformed_names_] = mapper.transform(df)\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def proc_df2(df, y_fld = None, skip_flds=None, do_scale=True, scale_col_exc = None, na_dict=None,\n",
    "             preproc_fn=None, max_n_cat=10, subset=None, mapper=None):\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset: df = get_sample(df,subset)\n",
    "    df = df.copy()\n",
    "    if preproc_fn: preproc_fn(df)\n",
    "    if y_fld is not None: \n",
    "        y = df[y_fld].values\n",
    "        df.drop(skip_flds+[y_fld], axis=1, inplace=True)\n",
    "\n",
    "    if na_dict is None: na_dict = {}\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if do_scale: mapper = scale_vars(df, mapper, scale_col_exc)\n",
    "    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    if y_fld is not None: \n",
    "        res = [pd.get_dummies(df, dummy_na=True), y, na_dict]\n",
    "    else:\n",
    "        res = [pd.get_dummies(df, dummy_na=True), na_dict]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def df_to_maxtrix(df, cols = cols):    \n",
    "    return df[cols].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# app train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/application_train.csv')\n",
    "train_cats(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_label = df_train.TARGET.values\n",
    "df_train.drop(columns = 'TARGET', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, _, _ = proc_df2(df_train,  do_scale=True, scale_col_exc = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk_id_curr = df_train.SK_ID_CURR.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_valid, y_train, y_valid = train_test_split(sk_id_curr, y_label, test_size=0.2, stratify = y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [i for i in df_train.columns if i not in ['SK_ID_CURR','SK_ID_PREV']]\n",
    "df_train_group = df_train.groupby(['SK_ID_CURR']).apply(lambda x: df_to_maxtrix(x, cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# cc train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cc_train = pd.read_csv('data/credit_card_balance.csv')\n",
    "train_cats(cc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cc_train.drop(columns = 'SK_ID_PREV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cc_train, _ = proc_df2(cc_train, do_scale = False, scale_col_exc = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cc_sk_id = set(cc_train['SK_ID_CURR'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cc_train = cc_train.sort_values(by = ['SK_ID_CURR', 'MONTHS_BALANCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [i for i in cc_train.columns if i not in ['SK_ID_CURR','SK_ID_PREV']]\n",
    "cc_train_group = cc_train.groupby(['SK_ID_CURR']).apply(lambda x: df_to_maxtrix(x, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -6. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -5. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -4. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -3. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -2. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -1. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_train_group[100006][:,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SortishSamplerRNN(Sampler):\n",
    "    def __init__(self, data_source, key, cc_sk_id, bs):\n",
    "        self.data_source, self.key, self.cc_sk_id, self.bs = data_source, key, cc_sk_id,bs\n",
    "    \n",
    "    def add_id(self, i): return i if len(i)%self.bs == 0 else i+[i[-1]]*(self.bs-len(i)%self.bs)\n",
    "    \n",
    "    def len_cal(self, i): \n",
    "        return self.key[self.data_source[i]].shape[0] if self.data_source[i] in self.cc_sk_id else 0\n",
    "\n",
    "    def __len__(self): return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):        \n",
    "        d={}\n",
    "        for i in range(len(self.data_source)): d.setdefault(self.len_cal(i), []).append(i)        \n",
    "        result = [d[n] for n in sorted(d, reverse=True)] \n",
    "        result = [self.add_id(i) for i in result]\n",
    "        result = [i for j in result for i in j]\n",
    "        return iter(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnarRNNDataset(Dataset):\n",
    "    def __init__(self, df, y):\n",
    "        n = len(df)\n",
    "        self.df = df\n",
    "        self.y = np.zeros((n,1)) if y is None else y\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx): return [self.df[idx], self.y[idx]] \n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls,df, y=None): return cls(df, y) \n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, df, y=None): return cls.from_data_frames(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnarRNNModelData(ModelData):\n",
    "    def __init__(self, path, trn_ds, val_ds, bs, tr_sampler = None, val_sampler = None, test_ds=None, shuffle=False):        \n",
    "        trn_dl = DataLoader(trn_ds, bs, shuffle=shuffle, sampler = tr_sampler, num_workers=1) #\n",
    "        val_dl = DataLoader(val_ds, bs, shuffle=shuffle, sampler = val_sampler, num_workers=1) #, \n",
    "        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n",
    "        super().__init__(path, trn_dl, val_dl, test_dl)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, path, \n",
    "                         trn_df, val_df, trn_y, val_y, \n",
    "                         tr_sampler = None, val_sampler = None,\n",
    "                         bs=64, test_df=None, shuffle=False):\n",
    "        trn_ds  = ColumnarRNNDataset.from_data_frame(trn_df,trn_y)\n",
    "        val_ds  = ColumnarRNNDataset.from_data_frame(val_df, val_y)\n",
    "        test_ds = ColumnarRNNDataset.from_data_frame(test_df, None) if test_df is not None else None\n",
    "        return cls(path, \n",
    "                   trn_ds, val_ds, bs, test_ds=test_ds, \n",
    "                   tr_sampler = tr_sampler, val_sampler = val_sampler, \n",
    "                   shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnarRNNModelData2(ColumnarRNNModelData):\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, path, \n",
    "                         trn_df, val_df, trn_y, val_y, \n",
    "                         tr_sampler = None, val_sampler = None,\n",
    "                         bs=64, test_df=None, shuffle=False):\n",
    "        trn_ds = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64; PATH = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_samp = SortishSamplerRNN(x_train, cc_train_group, cc_sk_id, bs=bs)\n",
    "val_samp = SortishSamplerRNN(x_valid, cc_train_group, cc_sk_id, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "md  = ColumnarRNNModelData.from_data_frames(PATH, \n",
    "                                            trn_df = x_train, val_df = x_valid, \n",
    "                                            trn_y = y_train, val_y = y_valid,\n",
    "                                            tr_sampler = trn_samp, val_sampler = val_samp,\n",
    "                                            shuffle=False, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, app_ref, cc_ref, cc_sk_id, szs, app_drop, cat_drop, rnn_drop, lin_drops, bs):        \n",
    "        super().__init__()\n",
    "        self.bs, self.cc_sk_id = bs, cc_sk_id       \n",
    "        self.app_ref, self.cc_ref = app_ref, cc_ref\n",
    "        \n",
    "        szs = [309] + szs\n",
    "        self.rnn = nn.GRU(input_size = 37, hidden_size = 64, num_layers = 2, dropout=rnn_drop)\n",
    "        \n",
    "        #linear layer\n",
    "        self.lins = nn.ModuleList([nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n",
    "        for o in self.lins: kaiming_normal(o.weight.data)\n",
    "        self.l_outp = nn.Linear(szs[-1], 1)\n",
    "        kaiming_normal(self.l_outp.weight.data)\n",
    "        #batchnorm layer\n",
    "        self.bns_app = nn.BatchNorm1d(245)\n",
    "        self.bns_lins = nn.ModuleList([nn.BatchNorm1d(sz) for sz in szs[1:]])\n",
    "        #dropout\n",
    "        self.app_drop = nn.Dropout(app_drop)\n",
    "        self.cat_drop = nn.Dropout(cat_drop)\n",
    "        self.drops_lins = nn.ModuleList([nn.Dropout(drop) for drop in lin_drops])\n",
    "        \n",
    "        self.zeros = V(torch.zeros(self.bs, 1, 37))\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        x_inp = x_in.cpu().data.numpy()\n",
    "        \n",
    "        app_input = torch.stack([V(i[0]) for i in self.app_ref[x_inp]])\n",
    "        app_input = self.app_drop(self.bns_app(app_input))\n",
    "        \n",
    "        cc_input = self.zeros if x_inp[0] not in self.cc_sk_id else torch.stack([V(i) for i in self.cc_ref[x_inp]])        \n",
    "        self.rnn.flatten_parameters()\n",
    "        outp,_ = self.rnn(cc_input)\n",
    "        \n",
    "        x = self.cat_drop(torch.cat([app_input, outp[:,-1,:]], 1))\n",
    "                                     \n",
    "        for linear,drop_out,batch_norm in zip(self.lins, self.drops_lins, self.bns_lins): \n",
    "            x = drop_out(batch_norm(F.relu(linear(x))))\n",
    "        x = F.sigmoid(self.l_outp(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imbalance_loss(inp,targ):\n",
    "    inp_flat = inp.view(-1); targ_flat = targ.float().view(-1)\n",
    "    return F.binary_cross_entropy(inp_flat, targ_flat, targ_flat + 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = RNNModel(app_ref = df_train_group, cc_ref = cc_train_group, \n",
    "             szs=  [400, 200, 100], \n",
    "             lin_drops = [0.15, 0.15, 0.25],\n",
    "             app_drop = 0.15, cat_drop = 0.15, rnn_drop = 0.2,\n",
    "             cc_sk_id = cc_sk_id, bs = bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RNN_learner = Learner.from_model_data(m, md)\n",
    "RNN_learner.crit = imbalance_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## inside model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([424713, 224283, 415461, 450171, 377005, 260304, 453933, 248617, 330204, 249270, 170463, 297895,\n",
       "       333630, 183329, 238781, 327531, 207461, 168190, 387621, 128421, 248332, 208383, 117152, 131243,\n",
       "       407891, 332435, 173751, 386240, 141924, 238534, 234970, 223769, 132120, 147180, 412491, 426472,\n",
       "       200196, 374149, 427889, 261825, 300192, 361145, 398680, 449413, 188868, 243526, 191388, 128089,\n",
       "       190101, 332167, 276902, 310027, 398777, 323515, 214678, 196818, 231733, 128713, 357860, 289818,\n",
       "       369460, 444766, 173101, 154987])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "app_in = torch.stack([V(i[0]) for i in m.app_ref[x.cpu().numpy()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " -0.5775   0.6166   0.5872  ...    1.0000   0.0000   0.0000\n",
       "  0.8073   0.3319  -0.6274  ...    1.0000   0.0000   0.0000\n",
       " -0.5775  -0.2374   0.3880  ...    1.0000   0.0000   0.0000\n",
       "           ...               ⋱              ...            \n",
       "  0.8073   0.1421   0.6280  ...    0.0000   0.0000   1.0000\n",
       " -0.5775   0.7115   1.8407  ...    1.0000   0.0000   0.0000\n",
       " -0.5775  -0.1995  -0.8734  ...    1.0000   0.0000   0.0000\n",
       "[torch.cuda.FloatTensor of size 64x245 (GPU 0)]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cc_input = torch.stack([V(i) for i in m.cc_ref[x.cpu().numpy()]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 96, 37])"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-9.6000e+01  8.9873e+04  1.8000e+05  ...   0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-9.5000e+01  8.8020e+04  1.8000e+05  ...   0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-9.4000e+01  8.5002e+04  1.8000e+05  ...   0.0000e+00  0.0000e+00  0.0000e+00\n",
       "                ...                   ⋱                   ...                \n",
       "-3.0000e+00  0.0000e+00  0.0000e+00  ...   0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.0000e+00  0.0000e+00  0.0000e+00  ...   0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-1.0000e+00  0.0000e+00  0.0000e+00  ...   0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.cuda.FloatTensor of size 96x37 (GPU 0)]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outp,_ = m.rnn(cc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 96, 64])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_cat = m.cat_drop(torch.cat([app_in, outp[:,-1,:]], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " -0.5775   0.6166   0.5872  ...   -0.2988  -0.3092  -0.5867\n",
       "  0.8073   0.3319  -0.6274  ...   -0.6520  -0.6392  -0.5300\n",
       " -0.5775  -0.2374   0.3880  ...   -0.6857  -0.7685  -0.7751\n",
       "           ...               ⋱              ...            \n",
       "  0.8073   0.1421   0.6280  ...   -0.9324  -0.9700   0.4383\n",
       " -0.5775   0.7115   1.8407  ...   -0.9285  -0.9688   0.4304\n",
       " -0.5775  -0.1995  -0.8734  ...   -0.9332  -0.9790   0.6781\n",
       "[torch.cuda.FloatTensor of size 64x309 (GPU 0)]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9910bc618045afb11065c3f5911b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.32909    0.352099  \n",
      "    1      0.323182   0.350866                                 \n",
      "    2      0.325351   0.352932                                 \n",
      "    3      0.327733   0.351974                                 \n",
      "    4      0.329273   0.35153                                  \n",
      "    5      0.328606   0.352933                                 \n",
      "    6      0.325109   0.353687                                 \n",
      "    7      0.323998   0.354662                                 \n",
      "    8      0.327932   0.354893                                 \n",
      "    9      0.320995   0.355032                                 \n",
      "    10     0.320868   0.354002                                 \n",
      "    11     0.327912   0.354857                                 \n",
      "    12     0.321223   0.353507                                 \n",
      "    13     0.3178     0.355163                                 \n",
      "    14     0.336139   0.36284                                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.36284])]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_learner.fit(lr, n_cycle = 5, cycle_len = 3, cycle_mult=1, use_wd_sched=True, wds=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "559px",
    "left": "1196px",
    "right": "78px",
    "top": "121px",
    "width": "326px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
