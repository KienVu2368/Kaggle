{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/home/dg/fastai'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_vars(df, mapper, scale_col_exc):\n",
    "    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n",
    "    if mapper is None:\n",
    "        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n]) and n not in scale_col_exc]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    df[mapper.transformed_names_] = mapper.transform(df)\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_df2(df, y_fld = None, skip_flds=None, do_scale=True, scale_col_exc = None, na_dict=None,\n",
    "             preproc_fn=None, max_n_cat=10, subset=None, mapper=None):\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset: df = get_sample(df,subset)\n",
    "    df = df.copy()\n",
    "    if preproc_fn: preproc_fn(df)\n",
    "    if y_fld is not None: \n",
    "        y = df[y_fld].values\n",
    "        df.drop(skip_flds+[y_fld], axis=1, inplace=True)\n",
    "\n",
    "    if na_dict is None: na_dict = {}\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if do_scale: mapper = scale_vars(df, mapper, scale_col_exc)\n",
    "    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    if y_fld is not None: \n",
    "        res = [pd.get_dummies(df, dummy_na=True), y, na_dict]\n",
    "    else:\n",
    "        res = [pd.get_dummies(df, dummy_na=True), na_dict]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_maxtrix(df, cols = cols):    \n",
    "    return df[cols].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# app train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/application_train.csv')\n",
    "train_cats(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = df_train.TARGET.values\n",
    "df_train.drop(columns = 'TARGET', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, _, _ = proc_df2(df_train,  do_scale=True, scale_col_exc = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_id_curr = df_train.SK_ID_CURR.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid, y_train, y_valid = train_test_split(sk_id_curr, y_label, test_size=0.2, stratify = y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [i for i in df_train.columns if i not in ['SK_ID_CURR','SK_ID_PREV']]\n",
    "df_train_group = df_train.groupby(['SK_ID_CURR']).apply(lambda x: df_to_maxtrix(x, cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cc train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train = pd.read_csv('data/credit_card_balance.csv')\n",
    "train_cats(cc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train.drop(columns = 'SK_ID_PREV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train, _ = proc_df2(cc_train, do_scale = False, scale_col_exc = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_sk_id = set(cc_train['SK_ID_CURR'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train = cc_train.sort_values(by = ['SK_ID_CURR', 'MONTHS_BALANCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [i for i in cc_train.columns if i not in ['SK_ID_CURR','SK_ID_PREV']]\n",
    "cc_train_group = cc_train.groupby(['SK_ID_CURR']).apply(lambda x: df_to_maxtrix(x, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -6. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -5. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -4. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -3. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -2. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ],\n",
       "       [    -1. ,      0. , 270000. ,      0. ,      0. ,      0. ,      0. ,      0. ,   2702.7,      0. ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_train_group[100006][:,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortishSamplerRNN(Sampler):\n",
    "    def __init__(self, data_source, key, cc_sk_id, bs):\n",
    "        self.data_source, self.key, self.cc_sk_id, self.bs = data_source, key, cc_sk_id,bs\n",
    "    \n",
    "    def add_id(self, i): return i if len(i)%self.bs == 0 else i+[i[-1]]*(self.bs-len(i)%self.bs)\n",
    "    \n",
    "    def len_cal(self, i): \n",
    "        return self.key[self.data_source[i]].shape[0] if self.data_source[i] in self.cc_sk_id else 0\n",
    "\n",
    "    def __len__(self): return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):        \n",
    "        d={}\n",
    "        for i in range(len(self.data_source)): d.setdefault(self.len_cal(i), []).append(i)        \n",
    "        result = [d[n] for n in sorted(d, reverse=True)]\n",
    "        #pdb.set_trace()\n",
    "        #result = [self.add_id(i) for i in result]\n",
    "        result = [i for j in result for i in j]\n",
    "        return iter(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnarRNNDataset(Dataset):\n",
    "    def __init__(self, df, y):\n",
    "        n = len(df)\n",
    "        self.df = df\n",
    "        self.y = np.zeros((n,1)) if y is None else y\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx): return [self.df[idx], self.y[idx]] \n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls,df, y=None): return cls(df, y) \n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, df, y=None): return cls.from_data_frames(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnarRNNModelData(ModelData):\n",
    "    def __init__(self, path, trn_ds, val_ds, bs, tr_sampler = None, val_sampler = None, test_ds=None, shuffle=False):        \n",
    "        trn_dl = DataLoader(trn_ds, bs, shuffle=shuffle, sampler = tr_sampler, num_workers=1) #\n",
    "        val_dl = DataLoader(val_ds, bs, shuffle=shuffle, sampler = val_sampler, num_workers=1) #, \n",
    "        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n",
    "        super().__init__(path, trn_dl, val_dl, test_dl)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, path, \n",
    "                         trn_df, val_df, trn_y, val_y, \n",
    "                         tr_sampler = None, val_sampler = None,\n",
    "                         bs=64, test_df=None, shuffle=False):\n",
    "        trn_ds  = ColumnarRNNDataset.from_data_frame(trn_df,trn_y)\n",
    "        val_ds  = ColumnarRNNDataset.from_data_frame(val_df, val_y)\n",
    "        test_ds = ColumnarRNNDataset.from_data_frame(test_df, None) if test_df is not None else None\n",
    "        return cls(path, \n",
    "                   trn_ds, val_ds, bs, test_ds=test_ds, \n",
    "                   tr_sampler = tr_sampler, val_sampler = val_sampler, \n",
    "                   shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64; PATH = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSamplerRNN(x_train, cc_train_group, cc_sk_id, bs=bs)\n",
    "val_samp = SortishSamplerRNN(x_valid, cc_train_group, cc_sk_id, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "md  = ColumnarRNNModelData.from_data_frames(PATH, \n",
    "                                            trn_df = x_train, val_df = x_valid, \n",
    "                                            trn_y = y_train, val_y = y_valid,\n",
    "                                            tr_sampler = trn_samp, val_sampler = val_samp,\n",
    "                                            shuffle=False, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, app_ref, cc_ref, cc_sk_id, szs, app_drop, cat_drop, rnn_drop, lin_drops, bs):        \n",
    "        super().__init__()\n",
    "        self.bs, self.cc_sk_id = bs, cc_sk_id       \n",
    "        self.app_ref, self.cc_ref = app_ref, cc_ref\n",
    "        \n",
    "        szs = [309] + szs\n",
    "        self.rnn = nn.GRU(input_size = 37, hidden_size = 64, num_layers = 2, dropout=rnn_drop)\n",
    "        \n",
    "        #linear layer\n",
    "        self.lins = nn.ModuleList([nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n",
    "        for o in self.lins: kaiming_normal(o.weight.data)\n",
    "        self.l_outp = nn.Linear(szs[-1], 1)\n",
    "        kaiming_normal(self.l_outp.weight.data)\n",
    "        #batchnorm layer\n",
    "        self.bns_app = nn.BatchNorm1d(245)\n",
    "        self.bns_lins = nn.ModuleList([nn.BatchNorm1d(sz) for sz in szs[1:]])\n",
    "        #dropout\n",
    "        self.app_drop = nn.Dropout(app_drop)\n",
    "        self.cat_drop = nn.Dropout(cat_drop)\n",
    "        self.drops_lins = nn.ModuleList([nn.Dropout(drop) for drop in lin_drops])\n",
    "        \n",
    "        self.zeros = V(torch.zeros(1, 37))\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        x_inp = x_in.cpu().data.numpy()\n",
    "        \n",
    "        app_input = torch.stack([V(i[0]) for i in self.app_ref[x_inp]])\n",
    "        app_input = self.app_drop(self.bns_app(app_input))\n",
    "        \n",
    "        self.rnn.flatten_parameters()\n",
    "        cc_inp = [V(self.cc_ref[i]) if i in self.cc_sk_id else self.zeros for i in x_inp]\n",
    "        lengths = [i.size()[0] for i in cc_inp] \n",
    "        max_length = cc_inp[0].size()[0]\n",
    "        pad_inp = torch.stack([nn.ConstantPad2d((0,0,0,max_length-i.size()[0]), 0)(i) for i in cc_inp])\n",
    "        cc_inp_pack = pack_padded_sequence(pad_inp, lengths, batch_first=True)\n",
    "        packed_output, _ = self.rnn(cc_inp_pack)\n",
    "        outp, _ = pad_packed_sequence(packed_output, batch_first=True)        \n",
    "        \n",
    "        x = self.cat_drop(torch.cat([app_input, outp[:,-1,:]], 1))\n",
    "                                     \n",
    "        for linear,drop_out,batch_norm in zip(self.lins, self.drops_lins, self.bns_lins): \n",
    "            x = drop_out(batch_norm(F.relu(linear(x))))\n",
    "        x = F.sigmoid(self.l_outp(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance_loss(inp,targ):\n",
    "    inp_flat = inp.view(-1); targ_flat = targ.float().view(-1)\n",
    "    return F.binary_cross_entropy(inp_flat, targ_flat, targ_flat + 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RNNModel(app_ref = df_train_group, cc_ref = cc_train_group, \n",
    "             szs=  [400, 200, 100], \n",
    "             lin_drops = [0.15, 0.15, 0.25],\n",
    "             app_drop = 0.15, cat_drop = 0.15, rnn_drop = 0.2,\n",
    "             cc_sk_id = cc_sk_id, bs = bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_learner = Learner.from_model_data(m, md)\n",
    "RNN_learner.crit = imbalance_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c05750898964f35a517eb487bc006a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.351355   0.353917  \n",
      "    1      0.349395   0.352241                                 \n",
      "    2      0.348675   0.35142                                  \n",
      "    3      0.348795   0.354273                                 \n",
      "    4      0.345298   0.351427                                 \n",
      "    5      0.347809   0.350964                                 \n",
      "    6      0.346332   0.353053                                 \n",
      "    7      0.347266   0.352368                                 \n",
      "    8      0.346588   0.35072                                  \n",
      "    9      0.341352   0.351263                                 \n",
      "    10     0.344679   0.352288                                 \n",
      "    11     0.339111   0.350885                                 \n",
      "    12     0.3464     0.352109                                 \n",
      "    13     0.34068    0.35142                                  \n",
      "    14     0.340474   0.349628                                 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.34963])]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_learner.fit(lr, n_cycle = 5, cycle_len = 3, cycle_mult=1, use_wd_sched=True, wds=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "559px",
    "left": "1196px",
    "right": "78px",
    "top": "121px",
    "width": "326px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
